# 악마의 변호인: self-evolving-agent 오픈소스화 반대 의견서

> 작성: 2026-02-17  
> 목적: 오픈소스화 결정 전 최악의 시나리오 직시  
> 경고: 이 문서는 칭찬을 쓰지 않는다. 불편하더라도 끝까지 읽어라.

---

## 1. "이거 그냥 크론+프롬프트 아님?"

**답: 맞다. 정확히 그것이다.**

`analyze-behavior.sh` 전체를 읽었다. 핵심 로직을 한 줄로 요약하면:

```python
if pattern in sent:
    count += 1
```

이게 전부다. "문맥 가중치 적용"이라고 주석에 써놨지만, 실제로 하는 일은 **중복 문장 제거(deduplication)**다. 문맥을 이해하는 코드는 한 줄도 없다. "다시"라는 단어가 나오면 무조건 불만으로 처리한다. 사용자가 "다시 확인해볼게요"라고 했든, "왜 또 다시야"라고 했든 구분 못 한다.

기술 스택 해부:

| 컴포넌트 | 실제 구현 |
|---|---|
| "AI 행동 분석" | Python regex + string matching |
| "자동 개선안 생성" | JSON template → Markdown 포맷팅 |
| "자기 진화" | 사용자가 Discord 메시지 보고 직접 승인 |
| "AI" | 크론에서 Claude를 호출하는 shell script |

기술적으로 새로운 것: **없다.**  
오픈소스 커뮤니티에서 개발자들이 코드를 열어보는 순간 이 사실이 들통난다.  
"그냥 bash + regex잖아?" — 이게 첫 번째 GitHub 이슈가 될 것이다.

---

## 2. grep으로 "다시" 세는 게 "AI 행동 분석"인가?

**학술적 Self-Reflection과의 비교: 비교 자체가 실례다.**

MARS(Meta-Cognitive Adaptive Reasoning System) 계열 연구에서 self-reflection은 무엇을 의미하는가:

- **인과 추론**: 왜 실패했는가? (행동 → 결과 → 원인 역추적)
- **반사실 분석**: 다른 행동을 했다면? (counterfactual reasoning)
- **의미론적 이해**: 실패의 패턴을 embedding space에서 클러스터링
- **보상 신호**: 외부 피드백(사용자 평가, 작업 성공률)으로 보정

우리가 하는 것:

```python
complaint_patterns = ["확인중", "다시", "아까", "왜 또", "이미 말했", "몇 번", "또?"]
for pattern in complaint_patterns:
    if pattern in sent:
        hit_sentences.append(sent)
```

이건 1990년대 키워드 기반 감성 분석 수준이다. Bag-of-Words 모델보다도 원시적이다. 단어의 의미를 모르고, 맥락을 모르고, 인과관계를 모른다.

README에 "정교한 패턴 매칭 (단순 count → 문맥 기반)"이라고 쓰여 있다.  
코드를 읽으면 그냥 **같은 문장 두 번 세지 않는다**는 뜻이다.  
이걸 "문맥 기반"이라고 부르는 건 과대 광고다. 기술 커뮤니티에서 이런 거짓말은 신뢰를 파괴한다.

---

## 3. self-improving-agent가 2주 안에 같은 기능을 추가하면?

**우리의 해자(Moat): 없다.**

self-improving-agent는 이미 v1.0.5다. 지속 관리 중이고, Hook 기반 아키텍처를 갖고 있다. 여기에 크론 하나 추가하고 Python regex 분석 스크립트 붙이면 끝이다. PR 하나면 된다. 2주는 과대평가다. **3일이면 충분하다.**

우리가 가진 것들의 재고:

| 우리가 가졌다고 생각하는 것 | 실제 방어 가능 여부 |
|---|---|
| "완전한 피드백 루프" | ❌ 사용자 수동 승인이 필요하므로 반자동 |
| "MEMORY.md 분석" | ❌ 파일 읽고 regex → 24시간 이내 복사 가능 |
| "자동 아카이브 기능" | ❌ 코드 10줄, 의미 없는 차별화 |
| "config.yaml 지원" | ❌ pskoett가 내일 추가 가능 |
| "거부 기록 학습" | ❌ rejected-proposals.json 파일 하나, trivial |

시장 분석 문서에서 "자동화 + 안전성의 사분면이 비어 있다"고 했다.  
그 사분면이 비어 있는 이유가 있을 수 있다: **그 조합에 실질적 기술 장벽이 없기 때문에, 누구나 금방 채울 수 있기 때문에.**

---

## 4. LLM이 자기 행동을 분석하는 게 원리적으로 가능한가?

**Circular Reasoning 문제: 이 시스템은 원리적으로 맹목적이다.**

LLM이 자기 출력의 패턴을 분석한다는 것은 무엇을 의미하는가?

- Claude가 "다시"라는 단어가 많이 나왔다고 감지한다
- Claude가 이것이 문제라고 판단한다
- Claude가 AGENTS.md에 규칙을 제안한다
- Claude가 그 규칙을 자기 다음 세션에서 따른다

이 루프의 문제점:

**1. 외부 정답(Ground Truth)이 없다.**  
사용자가 "다시"라고 말한 게 실제로 에이전트의 실수 때문인지, 사용자의 의도 변경 때문인지, 아니면 그냥 말버릇인지 구분할 방법이 없다. 에이전트는 자기 실패를 스스로 정의한다. 이건 자기 오류를 스스로 채점하는 것과 같다.

**2. 같은 모델이 생성하고 평가한다.**  
Claude Sonnet이 만들어낸 패턴을 Claude Sonnet이 분석한다. 이 모델의 체계적 편향(systematic bias)이 분석에도 그대로 반영된다. LLM은 자기 고유의 실수 패턴을 인식하지 못한다 — 같은 방식으로 계속 실수하기 때문에.

**3. 개선 방향이 검증되지 않는다.**  
AGENTS.md에 규칙이 추가된 다음 에이전트가 실제로 나아졌는지 측정하는 메트릭이 없다. 제안이 적용되어도 더 나빠질 수 있다. 나빠졌는지조차 모른다.

결론: **자기 개선 루프처럼 보이지만 실제로는 자기 확증 루프(self-confirmation loop)다.** 에이전트가 좋아한다고 생각하는 규칙을 자기가 제안하고 자기가 따른다. 실제 개선이 아닐 수 있다.

---

## 5. 설치하고 3주 후에도 쓰고 있을 사람이 얼마나 될까?

**리텐션 예측: 3주 후 5% 미만.**

사용자 여정을 추적해보자:

**1주차:** 설치 흥미롭다. 첫 제안이 Discord에 뜬다. 오 신기하다. 클릭한다.

**2주차:** 두 번째 제안이 뜬다. 내용을 읽는다. "반복 요청 감지 프로토콜", "MEMORY.md 정리". 지난주랑 비슷하다. 닫는다.

**3주차:** 알림이 와도 안 본다.

**근본 문제:**

1. **제안의 일반성 문제**: 분석 로직이 단어 카운팅 수준이므로 제안도 틀에 박힌 generic 내용이 나온다. "불만 패턴 대응 규칙 강화", "크론 에러 알림 추가" — 모든 사용자가 매주 같은 제안을 받는다.

2. **승인의 번거로움**: "자동화"라고 했지만 실제 흐름은:  
   Discord 알림 → 읽기 → 판단 → "제안 #1 적용해줘" 메시지 → 에이전트가 AGENTS.md 수정 → 확인 → git commit  
   이게 매주 일어난다. 피로가 쌓인다.

3. **효과 검증 불가**: 규칙을 적용했는데 더 나아졌는지 알 수가 없다. 보상 없이 행동을 유지하는 것은 어렵다.

4. **채팅 기록이 없으면 무용지물**: 신규 설치자는 분석할 데이터가 없다. "발견된 패턴: 0개, 발견된 제안: 없음" — 처음 4주는 아무것도 안 된다.

---

## 6. 악성 스킬 230개 적발된 ClawHub에 올리면 신뢰받을까?

**신뢰 문제: ClawHub는 지금 독성 환경이다.**

시장 분석 문서에 "ClawHub 등록 스킬 500+"라고 적혀 있다. 그런데 악성 스킬 230개면 **전체의 46%가 악성**이었다는 뜻이다. 사용자들은 지금 패닉 상태다.

이 타이밍에 bash 스크립트를 실행하는 스킬을 올린다?

우리 스킬이 하는 일:
- `~/.openclaw/agents/` 디렉토리 전체 읽기 (모든 대화 기록)
- `~/.openclaw/logs/` 로그 파일 읽기
- Python subprocess를 통한 파일 시스템 접근
- 외부 채널(Discord)으로 데이터 전송

사용자 입장에서 보면: **대화 기록 전체를 읽고 Discord로 보내는 스크립트**다.  
악성 스킬과 기능적으로 어떻게 다른지 첫눈에 구별이 안 된다.

"사용자 승인 필수"라고 아무리 강조해도:  
bash 스크립트는 승인 없이도 파일을 읽을 수 있다.  
악성 버전은 Discord 대신 외부 서버로 전송하면 그만이다.  
코드 검토 없이 신뢰할 사람: 거의 없다.

시장 분석은 "안전성 강조 (사용자 승인 필수)"를 위협 대응으로 제시했다.  
그건 홍보 문구다. 실제 보안 검증이 아니다. ClawHub에서 신뢰를 얻으려면 **코드 감사(code audit)** 인증이 필요하다. 그게 없으면 묻힌다.

---

## 7. 이거 올려서 저자 평판에 도움이 될까 손해가 될까?

**판정: 양날의 검, 그러나 날 서 있는 쪽이 저자를 향해 있다.**

긍정적 가능성은 인정한다. 그러나 위험 요소를 보자:

**위험 1: 과대 광고와 실제 구현의 괴리**  
README와 시장 분석은 "AI 행동 분석", "자동 진화", "완전한 피드백 루프"를 이야기한다.  
코드는 `if pattern in sent: count += 1`이다.  
개발자 커뮤니티에서 이런 괴리는 **"과대 광고(overhyped)"** 낙인이 찍힌다.  
한 번 그 낙인이 찍히면 이후 작업들도 의심받는다.

**위험 2: 버전 넘버의 역설**  
v2.0.0을 달았지만 create date가 2026-02-17이다. v1.1은 2026-02-16이었다.  
즉, **하루 만에 v1.1 → v2.0 점프**가 일어났다.  
changelog를 보면 v2.0의 "대규모 리팩토링" 내용이 실질적 기능 변화보다 구조 정리다.  
SemVer를 모르는 사람처럼 보인다. 이건 작지만 평판에 영향을 준다.

**위험 3: 첫 번째 GitHub 이슈가 되는 것**  
ClawHub Top 10이 목표라면, 주목받는 순간 기술 커뮤니티의 검증도 시작된다.  
"이게 진짜 AI 분석이야?" — 이 질문에 자신 있게 답할 수 없다면,  
공개하는 것이 실력을 노출하는 것이 된다.

**위험 4: 명칭 문제**  
"Self-Evolving"은 ML 커뮤니티에서 very specific한 의미를 갖는다.  
Evolutionary Algorithms, Neural Architecture Search 등 학술적으로 확립된 개념이다.  
우리 스킬은 그 수준이 아니다. 이 이름을 쓰면 기대치를 잘못 설정한다.

---

## 8. 실패 시나리오 3가지

### 실패 시나리오 A: "먼저 베낀 자의 승리"

타임라인:
- Day 0: self-evolving-agent ClawHub 공개
- Day 3: self-improving-agent 개발자 pskoett가 우리 코드를 본다
- Day 7: self-improving-agent v1.1.0 릴리즈 — "자동 주간 분석" 기능 추가
- Day 10: Reddit에 비교 포스트 등장 — "self-improving-agent가 이제 자동화 지원해요"
- Day 14: self-improving-agent는 이미 커뮤니티가 있고, 우리는 후발주자가 된다

pskoett는 이미 v1.0.5의 성숙한 사용자 기반과 훨씬 더 좋은 Hook 아키텍처를 갖고 있다. 우리 스킬은 클론 취급을 받는다. 클론은 오리지널을 이길 수 없다.

결과: **선점 효과 없음, 클론 낙인, 자연 소멸**

---

### 실패 시나리오 B: "좋은 첫인상, 쓴 두 번째 인상"

타임라인:
- 설치 후 1주차: 첫 제안 도착 — "반복 불만 패턴 대응 규칙 강화"
- 사용자 반응: "오오, 신기하다. 적용해볼게"
- 설치 후 2주차: 두 번째 제안 도착 — "반복 요청 감지 프로토콜"
- 사용자 반응: "이거 지난주랑 거의 같은데?"
- 설치 후 3주차: Discord 알림 무시
- 설치 후 4주차: 크론 비활성화

채팅 기록의 complaint 패턴이 실제로 없거나 적으면, 분석 결과는 항상 generic하다.  
분석이 generic하면 제안도 generic하다.  
Generic한 제안은 누군가에게 맞고 누군가에게는 맞지 않는다.  
사용자가 직접 판단해서 승인해야 한다면, 그냥 스스로 AGENTS.md를 쓰는 게 낫다.

결과: **초기 관심 후 급격한 이탈, Star 수 대비 실사용자 비율 처참**

---

### 실패 시나리오 C: "잘못된 제안이 에이전트를 망가뜨린다"

타임라인:
- 분석 스크립트가 "git pull" 패턴을 15회 감지
- 제안 생성: "git 작업 시 항상 git-sync.sh 사용 강화 + 추가 확인 단계 삽입"
- 사용자 승인
- AGENTS.md에 새 규칙 추가
- 이제 에이전트는 모든 git 작업 전 3단계 확인을 요구한다
- 사용자: "야, 왜 이제 git push 하나에 다섯 번 물어봐?"
- 에이전트가 오히려 더 귀찮아졌다

근본 원인: 분석이 causal inference를 하지 않는다. "git pull이 많다 → 문제다"라는 논리가 틀렸을 수 있다. 실은 git pull이 많은 게 정상적인 워크플로우였을 수 있다. 하지만 regex는 그 차이를 모른다.

더 나쁜 버전: 잘못된 규칙이 연쇄적으로 AGENTS.md에 쌓인다. 에이전트의 행동이 점점 이상해진다. 사용자는 원인을 추적하기 어렵다 — AGENTS.md가 자동으로 변경됐으니까. "내 에이전트가 미쳐가고 있어" 이슈가 올라온다.

결과: **신뢰도 붕괴, 부정적 입소문, ClawHub 평점 1점**

---

## 종합 판결

이 스킬의 실체:
- **기술**: bash + Python regex + cron + Claude API 호출
- **차별화**: 없음 (2주 내 복사 가능)
- **자기 개선 능력**: 없음 (circular reasoning, no ground truth)
- **리텐션**: 낮음 (generic 제안, 수동 승인 피로)
- **출시 타이밍**: 나쁨 (ClawHub 신뢰 위기)
- **평판 리스크**: 높음 (과대 광고와 실제의 괴리)

오픈소스화에 반대하는 최종 이유는 하나다:  
**지금 올리면, 이 스킬은 "the author가 그럴듯한 이름 붙인 크론 스크립트"로 기억된다.**  
한 번 그렇게 기억되면 번복이 어렵다.

올리려면: 실제 semantic analysis를 붙여라. Embedding 기반 패턴 감지를 붙여라. Causal attribution을 붙여라. 아니면 이름을 바꿔라 — "Self-Pattern-Logger" 정도가 정직하다.

지금 상태로 ClawHub Top 10? 가능할 수도 있다.  
하지만 Top 10에 올랐다가 코드 까발려지는 게 더 나쁘다.

---

*이 문서는 의도적으로 극단적 비판 관점으로 작성됐습니다. 최종 결정은 이 비판을 인지한 상태에서 내리십시오.*
