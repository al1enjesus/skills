#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹é©å®—ä¹¦ç±ä¹å›­æœç´¢è„šæœ¬ (Reformed Books Search)
æœç´¢ http://www.https.ng:1234 ä¸Šçš„åŸºç£æ•™ç¥å­¦ä¹¦ç±
"""

import argparse
import io
import json
import re
import sys
import urllib.parse
import urllib.request
from html.parser import HTMLParser
from typing import List, Dict, Optional

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

SEARCH_URL = "http://www.https.ng:1234"
BROWSE_URL = "http://www.https.ng"

class SearchResultParser(HTMLParser):
    """è§£ææœç´¢ç»“æœé¡µé¢"""
    def __init__(self):
        super().__init__()
        self.results: List[Dict] = []
        self.in_result_row = False
        self.in_link = False
        self.current_result: Dict = {}
        self.current_data = ""
        self.cell_index = 0
        
    def handle_starttag(self, tag, attrs):
        attrs_dict = dict(attrs)
        if tag == 'tr' and 'class' in attrs_dict:
            self.in_result_row = True
            self.current_result = {}
            self.cell_index = 0
        elif tag == 'a' and self.in_result_row:
            self.in_link = True
            href = attrs_dict.get('href', '')
            if href and not href.startswith('#'):
                self.current_result['url'] = href
                
    def handle_endtag(self, tag):
        if tag == 'tr' and self.in_result_row:
            if self.current_result.get('name'):
                self.results.append(self.current_result)
            self.in_result_row = False
        elif tag == 'td' and self.in_result_row:
            data = self.current_data.strip()
            if self.cell_index == 0 and data:
                self.current_result['name'] = data
            elif self.cell_index == 1:
                self.current_result['path'] = data
            elif self.cell_index == 2:
                self.current_result['size'] = data
            elif self.cell_index == 3:
                self.current_result['date'] = data
            self.cell_index += 1
            self.current_data = ""
        elif tag == 'a':
            self.in_link = False
            
    def handle_data(self, data):
        if self.in_result_row:
            self.current_data += data


def search_books(keywords: str, format_filter: Optional[str] = None, limit: int = 20) -> List[Dict]:
    """
    æœç´¢ä¹¦ç±
    
    Args:
        keywords: æœç´¢å…³é”®è¯ï¼Œç©ºæ ¼åˆ†éš”
        format_filter: æ–‡ä»¶æ ¼å¼è¿‡æ»¤ (pdf, epub, mobi, doc, txt)
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    # æ·»åŠ æ ¼å¼åˆ°å…³é”®è¯
    search_query = keywords
    if format_filter and format_filter.lower() not in keywords.lower():
        search_query = f"{keywords} {format_filter}"
    
    # æ„å»ºæœç´¢ä¿¡æ¯
    results = []
    
    # ç”±äºè¯¥ç½‘ç«™ä½¿ç”¨ JavaScript å‰ç«¯æœç´¢ï¼Œæ— æ³•ç›´æ¥é€šè¿‡ HTTP è¯·æ±‚è·å–ç»“æœ
    # è¿”å›æœç´¢æŒ‡å¯¼ä¿¡æ¯
    print(f"\nğŸ“š æ”¹é©å®—ä¹¦ç±ä¹å›­æœç´¢")
    print(f"{'='*50}")
    print(f"\nğŸ” æœç´¢å…³é”®è¯: {search_query}")
    print(f"\nğŸ“Œ è¯·åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä»¥ä¸‹é“¾æ¥è¿›è¡Œæœç´¢:")
    print(f"\n   {SEARCH_URL}")
    print(f"\nğŸ’¡ æœç´¢æ­¥éª¤:")
    print(f"   1. åœ¨æœç´¢æ¡†è¾“å…¥: {search_query}")
    print(f"   2. ç‚¹å‡» 'ğŸ” æœç´¢' æŒ‰é’®")
    print(f"   3. ç‚¹å‡»æ–‡ä»¶åå³å¯ä¸‹è½½")
    
    if format_filter:
        print(f"\nğŸ“ å·²æ·»åŠ æ ¼å¼è¿‡æ»¤: {format_filter}")
        print(f"   æˆ–ä½¿ç”¨ä¸‹æ‹‰èœå•é€‰æ‹© '{format_filter}' æ ¼å¼")
    
    print(f"\nğŸ”— å…¶ä»–æœ‰ç”¨é“¾æ¥:")
    print(f"   â€¢ é«˜çº§æœç´¢: http://www.https.ng:5757")
    print(f"   â€¢ èµ„æºå¯¼èˆª: http://www.https.ng:1234/0.html")
    print(f"   â€¢ åœ¨çº¿æµè§ˆ: {BROWSE_URL}")
    
    # å°è¯•é€šè¿‡ç®€å•è¯·æ±‚è·å–ä¸€äº›ä¿¡æ¯
    try:
        # å°è¯•è®¿é—®ä¸»ç«™è·å–åŸºæœ¬ä¿¡æ¯
        req = urllib.request.Request(
            BROWSE_URL,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        with urllib.request.urlopen(req, timeout=10) as response:
            if response.status == 200:
                print(f"\nâœ… ç½‘ç«™å¯è®¿é—®")
    except Exception as e:
        print(f"\nâš ï¸  ç½‘ç«™å¯èƒ½æš‚æ—¶æ— æ³•è®¿é—®ï¼Œè¯·ç¨åé‡è¯•")
        print(f"   é”™è¯¯: {e}")
    
    print(f"\n{'='*50}")
    
    return results


def format_results(results: List[Dict], prefer_pdf: bool = True) -> str:
    """
    æ ¼å¼åŒ–æœç´¢ç»“æœ
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
        prefer_pdf: æ˜¯å¦ä¼˜å…ˆæ˜¾ç¤º PDF
    
    Returns:
        æ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
    """
    if not results:
        return "æœªæ‰¾åˆ°ç»“æœ"
    
    # PDF ä¼˜å…ˆæ’åº
    if prefer_pdf:
        results.sort(key=lambda x: (
            0 if x.get('name', '').lower().endswith('.pdf') else 1,
            x.get('name', '')
        ))
    
    output = []
    for i, r in enumerate(results, 1):
        name = r.get('name', 'æœªçŸ¥')
        url = r.get('url', '')
        size = r.get('size', '')
        date = r.get('date', '')
        
        output.append(f"{i}. {name}")
        if size:
            output.append(f"   å¤§å°: {size}")
        if date:
            output.append(f"   æ—¥æœŸ: {date}")
        if url:
            output.append(f"   ä¸‹è½½: {url}")
        output.append("")
    
    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(
        description='æœç´¢æ”¹é©å®—ä¹¦ç±ä¹å›­ (https.ng)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s "ç³»ç»Ÿç¥å­¦"
  %(prog)s "åŠ å°”æ–‡ è¦ä¹‰" --format pdf
  %(prog)s "å¨æ–¯æ•æ–¯ç‰¹ ä¿¡æ¡"
  %(prog)s "æ¸…æ•™å¾’" --format epub
        """
    )
    parser.add_argument('keywords', help='æœç´¢å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”')
    parser.add_argument('--format', '-f', dest='format_filter',
                        choices=['pdf', 'epub', 'mobi', 'doc', 'txt', 'azw3', 'ppt'],
                        help='æ–‡ä»¶æ ¼å¼è¿‡æ»¤')
    parser.add_argument('--limit', '-l', type=int, default=20,
                        help='ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 20)')
    parser.add_argument('--json', '-j', action='store_true',
                        help='ä»¥ JSON æ ¼å¼è¾“å‡º')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œæœç´¢
    results = search_books(
        args.keywords,
        format_filter=args.format_filter,
        limit=args.limit
    )
    
    if args.json:
        print(json.dumps({
            'keywords': args.keywords,
            'format': args.format_filter,
            'search_url': SEARCH_URL,
            'results': results
        }, ensure_ascii=False, indent=2))


if __name__ == '__main__':
    main()
